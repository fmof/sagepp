// Header for word-based topic models

#ifndef ISAGE_WTM_SAGE_H_
#define ISAGE_WTM_SAGE_H_

#include "concrete.hpp"
#include "dmc.hpp"
#include "mathops.hpp"
#include "util.hpp"
#include "wtm.hpp"

#include <fstream>
#include <iostream>
#include "stdlib.h"
#include <time.h>

// for pair
#include "map"
#include <utility>
#include <unordered_set>
#include <string>
#include <vector>

#include <fstream>
#include <boost/algorithm/string.hpp>
#include <boost/serialization/unordered_map.hpp>
#include <boost/serialization/vector.hpp>

namespace isage {
  namespace wtm {
    template <typename EtaType>
    class SageTopic {
    protected:
      typedef std::vector<double> TauType;
      int support_size_;
      double tau_hyper_;
      TauType tau_;
      EtaType eta_;
    public:
      SageTopic<EtaType>(int support_size, double kappa) : support_size_(support_size), tau_hyper_(kappa), tau_(support_size), eta_(support_size) {
      }
      double& operator[](const size_t& idx) {
	return eta_[idx];
      }      
    };

    class DenseSageTopic : public SageTopic<std::vector<double> > {
    public:
      DenseSageTopic(int support_size, double kappa) : SageTopic<std::vector<double> >(support_size, kappa) {
      }
    };
    /**
     * Variational inference for SAGE (sparse additive 
     * generative models, by Eisenstein et al. 2011).
     * This assumes that each observation is generated by a
     * categorical (discrete) distribution with a general
     * exponential family parametrization.
     */
    template <typename D, typename W, typename S>
    class SageVariational {
    private:
      typedef Vocabulary<W> V;
      typedef DiscreteLDA<W, S > M;
      const int num_docs;

      std::vector< std::vector< int> >  assignments;
      // count tables
      std::vector< std::vector< int> >  c_doc_topic;
      // num_docs * num_topic;
      std::vector< std::vector< int> >  c_topic;
      // num_topics
      std::vector<int> c_topic_sums;

      std::vector<int>* c_doc_topic_ptr;

      // the model itself
      M* model;
      Corpus<D>* corpus_;
      V* vocab_;

      int num_topics_;

      std::vector<int> num_words;

      dmc::gdmc topic_dmc;
      dmc::gdmc word_dmc;
    
      int current_word_index = -1;

    public:
      SageVariational<D, W, S>(M* model, Corpus<D>* corpus, V* vocab) :
      num_docs(corpus->num_docs()), model(model), corpus_(corpus), vocab_(vocab), num_topics_(model->num_topics()) {
	int num_docs = corpus->num_docs();
	for(int d = 0; d < num_docs; d++) {
	  const int nw = ((*corpus)[d]).num_words();
	  num_words.push_back(nw);
	  c_doc_topic.push_back(std::vector<int>(num_topics_));
	  assignments.push_back(std::vector<int>(nw));
	}
	const int vocab_size = vocab->num_words();
	for(int t = 0; t < model->num_topics(); t++) {
	  c_topic_sums.push_back(0);
	  c_topic.push_back(std::vector<int>(vocab_size));
	}
	word_dmc = dmc::gdmc(vocab_size, model->hyper_word(), model->num_topics());
	topic_dmc = dmc::gdmc(model->num_topics(), model->hyper_theta(), num_docs);
      }
      ~SageVariational() {
      }
      int sample_topic() {
	std::vector<double> lps(num_topics_);
	for(int topic_idx = 0; topic_idx < num_topics_; topic_idx++) {
	  double inner = word_dmc.log_u_conditional(current_word_index, c_topic[topic_idx], c_topic_sums[topic_idx], 1);
	  inner += topic_dmc.log_u_conditional(topic_idx, *c_doc_topic_ptr, num_docs, 1);
	  lps[topic_idx] = inner;
	}
	return dmc::cat::log_u_sample(lps);
      }

      void init() {
	for(int di = 0; di < num_docs; di++){
	  const int num_w = num_words[di];
	  D doc = (*corpus_)[di];
	  for(int wi = 0; wi < num_w; wi++){
	    // randomly assign to a topic
	    int topic = wi % model->num_topics();
	    assignments[di][wi] = topic;
	    ++c_doc_topic[di][topic];
	    ++c_topic[topic][ vocab_->index(doc[wi]) ];
	    ++c_topic_sums[topic];
	  }
	}
      }

      void learn(const int iter_offset = 0) {
      }

      // transfer the learned parameters back to the model
      void transfer_learned_parameters() {
	model->prior_topic(topic_dmc.collapsed_params());
	model->prior_word(word_dmc.collapsed_params());      
      }

    };
  }
}

#endif
