// Header for word-based topic models

#ifndef ISAGE_WTM_SAGE_LIMMEM_H_
#define ISAGE_WTM_SAGE_LIMMEM_H_

#include "dmc.hpp"
#include "loglin.hpp"
#include "mathops.hpp"
#include "optimize.hpp"
#include "sage_defs.hpp"
#include "util.hpp"
#include "wtm.hpp"

#include <fstream>
#include <iostream>
#include <ostream>
#include "stdlib.h"
#include <time.h>

// for pair
#include "map"
#include <cmath>
#include <limits>
#include <utility>
#include <unordered_set>
#include <thread>
#include "omp.h"
#include "lock.hpp"
#include <string>
#include <vector>

#include <boost/algorithm/string.hpp>
#include <boost/serialization/unordered_map.hpp>
#include <boost/serialization/vector.hpp>


namespace isage {
  namespace wtm {
    /**
     * Variational inference for SAGE (sparse additive 
     * generative models, by Eisenstein et al. 2011).
     * This assumes that each observation is generated by a
     * categorical (discrete) distribution with a general
     * exponential family parametrization.
     */
    template <typename D, typename W, typename TopicType>
    class SageVariationalLimMem {
    private:
      typedef Vocabulary<W> V;
      //typedef DiscreteLDA<W, TopicType > M;
      typedef std::vector<double> ModelTopicType;
      typedef DiscreteLDA<W, ModelTopicType > M;
      typedef typename D::WordCountType WordCountType;
      int num_docs_;

      // Documents x Topics
      std::vector< std::vector< double > > var_topic_usage_params_;
      // This member is Dense x Sparse
      std::vector< std::vector< int > > words_in_docs_;
      // This member is Dense x Sparse
      typename std::vector< std::vector< WordCountType > > word_type_counts_;
      // As this is a more memory-efficient inference method,
      // we don't store all assignment parameters.

      // pointer to background distribution
      std::vector< double >* background_;

      // words x topics: this is for easy updates in the tight inner loop
      // it's not optimal when updating the topic parameters themselves, but
      // that's done (relatively) infrequently
      std::vector< std::vector< double > > expected_counts_;

      std::vector< TopicType* > topics_;

      // the model itself
      M* model_;
      Corpus<D>* corpus_;
      V* vocab_;

      int num_topics_;

      std::vector<double> word_hypers_;
      std::vector<double> usage_hypers_;

      std::vector<std::vector<double> > prev_usages;

      std::vector< Mutex > expected_mutexes_;

      bool own_background;
      bool own_topics;

      void zero_expected_counts() {
	for(std::vector< std::vector< double> >::iterator it = expected_counts_.begin();
	    it != expected_counts_.end(); ++it) {
	  std::fill(it->begin(), it->end(), 0.0);
	}
      }

      friend class boost::serialization::access;
      // When the class Archive corresponds to an output archive, the
      // & operator is defined similar to <<.  Likewise, when the class Archive
      // is a type of input archive the & operator is defined similar to >>.
      template<class Archive>
      void serialize(Archive& ar, const unsigned int version) {
        ar & num_topics_;
        ar & background_;
        ar & topics_;
        ar & vocab_;
        ar & word_hypers_;
        ar & usage_hypers_;
        ar & words_in_docs_;
	ar & var_topic_usage_params_;
      } 

    public:
      SageVariationalLimMem<D, W, TopicType>() : background_(NULL), model_(NULL), corpus_(NULL) {
	own_background = false;
	own_topics = false;
      }
      SageVariationalLimMem<D, W, TopicType>(M* model, Corpus<D>* corpus, V* vocab, isage::wtm::SageTopicRegularization reg_how) :
      num_docs_(corpus->num_docs()),  
        topics_(std::vector<TopicType*>()),
	model_(model), corpus_(corpus), vocab_(vocab), 
	num_topics_(model->num_topics()), 
        word_hypers_(model_->hyper_word()), usage_hypers_(model_->hyper_theta()) {
        background_ = new std::vector<double>(vocab_->num_words(), 0.0);
        for(int t = 0; t < num_topics_; ++t) {
          TopicType* topic = new TopicType(vocab_->num_words(), 1.0, reg_how);
          topics_.push_back(topic);
        }
	own_background = true;
	own_topics = true;
      }
      ~SageVariationalLimMem() {
	if(own_topics) {
	  for(int t = 0; t < num_topics_; ++t) {
	    delete topics_[t];
	  }
	}
	if(own_background) {
	  delete background_;
	}
      }
      void var_topic_usage_params(size_t i, const std::vector<double>& row) {
	var_topic_usage_params_[i] = row;
      }
      const std::vector<std::vector<double> > var_topic_usage_params() {
	return var_topic_usage_params_;
      }
      const std::vector<std::vector<WordCountType > >& word_type_counts() {
        return word_type_counts_;
      }
      void word_type_counts(const std::vector<std::vector<WordCountType > >& info) {
	word_type_counts_ = info;
      }
      const std::vector<std::vector<int> >& words_in_docs() {
	return words_in_docs_;
      }
      void words_in_docs(const std::vector<std::vector<int> >& info) {
	words_in_docs_ = info;
      }
      const std::vector< std::vector< double > >& expected_counts() {
	return expected_counts_;
      }

      void word_hypers(const std::vector<double>& f) {
	word_hypers_ = f;
      }
      std::vector<double>& word_hypers() {
	return word_hypers_;
      }
      void usage_hypers(const std::vector<double>& f) {
	usage_hypers_ = f;
      }
      std::vector<double>& usage_hypers() {
	return usage_hypers_;
      }

      void num_topics(int nt) {
	num_topics_ = nt;
      }
      int num_topics() {
	return num_topics_;
      }

      void corpus(Corpus<D>* corpus) {
        corpus_ = corpus;
        if(num_docs_ != corpus_->num_docs()) {
          WARN << "The number of docs has changed from " << num_docs_ << " to " << corpus_->num_docs() << ". Please call reinit().";
        }
        num_docs_ = corpus_->num_docs();
      }
      void model(M* model) {
        model_ = model;
      }
      M reconstruct_model() {
        M model(this->num_topics_);
        model.hyper_theta(this->usage_hypers_);
        model.hyper_word(this->word_hypers_);
        this->update_model(&model);
        return model;
      }
      void vocab(V* vocab) {
	vocab_ = vocab;
      }
      V* vocab() {
        return vocab_;
      }
      void background(std::vector<double>* b) {
	background_ = b;
	own_background = false;
      }
      std::vector<double>* background() {
	return background_;
      }
      void topics(const std::vector<TopicType*>& topics) {
	topics_ = topics;
      }
      std::vector<TopicType*>& topics() {
	return topics_;
      }
      TopicType* topic(size_t t) {
	return topics_[t];
      }

      /**
       * SageVariationalInitializer must have four functions:
       */
      template <typename SageVariationalInitializer>
      void init(SageVariationalInitializer vi) {
	int num_words = 0;
	for(int d = 0; d < num_docs_; d++) {
	  const D& doc = (*corpus_)[d];
	  var_topic_usage_params_.push_back(vi.usage(model_->hyper_theta(), doc.num_words()));
	  const typename D::Multinomial doc_multi = doc.multinomial();
	  std::vector<int> word_types;
	  std::vector<WordCountType> wcounts;
	  for(const auto& count_pair : doc_multi) {
	    const int word = vocab_->index(count_pair.first);
	    word_types.push_back(word);
	    wcounts.push_back(count_pair.second);
	    background_->operator[](word) += count_pair.second;
	    num_words += count_pair.second;
	  }
	  words_in_docs_.push_back(word_types);
	  word_type_counts_.push_back(wcounts); 
	}
	// initialize expected counts
	const int vocab_size = const_cast<V*>(vocab_)->num_words();
	for(int wi = 0; wi < vocab_size; ++wi) {
	  expected_counts_.push_back(std::vector<double>(num_topics_, 0.0));
	  expected_mutexes_.push_back(isage::Mutex());
	}
	// note that expected topic counts are initialized in the initialization list
	// now finish the background initialization
	complete_background_init(num_words);
        // topic initialization MUST come after background initialization
        // to avoid segfaults
	omp_set_num_threads(vi.num_threads());
#pragma omp parallel for
        for(int t = 0; t < model_->num_topics(); t++) {
	  INFO << "Starting to initialize topic " << t;
	  topics_[t]->eta( vi.topic(model_->hyper_word(), corpus_, vocab_, background_) );
	  INFO << "Done initializing topic " << t;
	}
      }

      /**
       * SageVariationalInitializer must have four functions:
       */
      template <typename SageVariationalInitializer>
      void reinit(SageVariationalInitializer vi) {
	int num_words = 0;
	words_in_docs_.clear();
	word_type_counts_.clear();
	var_topic_usage_params_.clear();
	for(int d = 0; d < num_docs_; d++) {
	  const D& doc = (*corpus_)[d];
	  var_topic_usage_params_.push_back(vi.usage(model_->hyper_theta(), doc.num_words()));
	  const typename D::Multinomial doc_multi = doc.multinomial();
	  std::vector<int> word_types;
	  std::vector<WordCountType> wcounts;
	  for(const auto& count_pair : doc_multi) {
	    const int word = vocab_->index(count_pair.first);
	    word_types.push_back(word);
	    wcounts.push_back(count_pair.second);
	    num_words += count_pair.second;
	  }
	  words_in_docs_.push_back(word_types);
	  word_type_counts_.push_back(wcounts);
	}
	expected_counts_.clear();
	// initialize expected counts
	const int vocab_size = const_cast<V*>(vocab_)->num_words();
	for(int wi = 0; wi < vocab_size; ++wi) {
	  expected_counts_.push_back(std::vector<double>(num_topics_, 0.0));
	  expected_mutexes_.push_back(isage::Mutex());
	}
	for(int topic_id = 0; topic_id < num_topics_; ++topic_id) {
	  topics_[topic_id]->prepare();
	  topics_[topic_id]->push_to_maxent();
	}
      }

      void alloc() {
	words_in_docs_.clear();
	word_type_counts_.clear();
	var_topic_usage_params_.clear();
	for(int d = 0; d < num_docs_; d++) {
	  const D& doc = (*corpus_)[d];
	  var_topic_usage_params_.push_back(std::vector<double>(num_topics_,0.0));
	  const typename D::Multinomial doc_multi = doc.multinomial();
	  words_in_docs_.push_back(std::vector<int>(doc_multi.size(),0));
	  word_type_counts_.push_back(std::vector<WordCountType>(doc_multi.size(),0));
	}
	expected_counts_.clear();
	// initialize expected counts
	const int vocab_size = const_cast<V*>(vocab_)->num_words();
	for(int wi = 0; wi < vocab_size; ++wi) {
	  expected_counts_.push_back(std::vector<double>(num_topics_, 0.0));
	  expected_mutexes_.push_back(isage::Mutex());
	}
      }

      void propagate_background() {
	for(int topic_id = 0; topic_id < num_topics_; ++topic_id) {
	  topics_[topic_id]->background(background_);
	}
      }

      void renormalize_topics() {
        for(int t = 0; t < num_topics_; ++t) {
          topics_[t]->renormalize();
        }
      }

      void complete_background_init(int num_words, double min_log_prob = -200, double min_freq = 0.0001) {
	// make sure there are no zero counts
	isage::util::ensure_min(min_freq, background_);
	// divide by the total number of words in the corpus
	isage::util::scalar_product(1.0/(double)num_words, background_);
	// now log it all
	isage::util::log(background_);
	// truncate to min_log_prob
	isage::util::ensure_min(min_log_prob, background_);
	// renormalize
	dmc::cat::log_renormalize(background_);
	// and now set each of the topic's background params to &background_
	propagate_background();
      }

      // This is the same as in normal (original, unsmoothed) LDA.
      // Note that this also computes the expected counts.
      void update_var_assignments(int doc_index, int word, int word_count,
				  std::vector<double>* vaptr) {
	for(size_t idx = 0; idx < (size_t)num_topics_; ++idx) {
	  vaptr->operator[](idx) += topics_[idx]->l_probability(word);
	}
	double lnorm = mathops::log_sum_exp(*vaptr);
	isage::util::sum(-1 * lnorm, vaptr);
	isage::util::exp(vaptr);
	//also, update the expected counts
        isage::util::linear_combination_in_first(&(expected_counts_[word]),
						 *vaptr,
                                                 1.0, (double)word_count);
      }

      // This is the same as in normal LDA.
      void update_usage(int doc_index, const std::vector<std::vector<double> >& var_assign) {
	const std::vector<int>& words = words_in_docs_[doc_index];
	std::vector<double> accumulator(num_topics_, 0.0);
	for(size_t i = 0; i < words.size(); ++i) {
	  const int count = word_type_counts_[doc_index][i];
          isage::util::linear_combination_in_first(&accumulator,
                                                   var_assign[i],
                                                   1.0, (double)count);
	}
	var_topic_usage_params_[doc_index] = usage_hypers_;
	isage::util::sum_in_first(&(var_topic_usage_params_[doc_index]), 
                                  accumulator);
      }

      void update_topic(int topic_index) {
	INFO << "Beginning to fit topic " << topic_index;
        TopicType* sage_topic = topics_[topic_index];
        // computing the gradient requires munging the expected counts to form "data"
        // this means we need the column slice of the expected counts
        std::vector<double> usable_counts = 
          isage::util::column(expected_counts_, topic_index);
	int opt_status = sage_topic->fit_topic(&usable_counts, 1.0);
	INFO << "Topic " << topic_index << " has optimization status " << opt_status;
      }
      void update_topics(const SageStrategy& strategy) {
	if(strategy.num_m_threads == 1) {
	  for(int ti = 0; ti < num_topics_; ++ti) {
	    update_topic(ti);
	  }
	} else {
	  omp_set_num_threads(strategy.num_m_threads);
#pragma omp parallel for
	  for(int ti = 0; ti < num_topics_; ++ti) {
	    update_topic(ti);
	  }
	}
      }

      inline void get_usage_estimates(std::vector<std::vector<double> >*  usage_ptr) {
        for(const auto& use : var_topic_usage_params_) {
          const double norm = isage::util::sum(use);
          usage_ptr->push_back(isage::util::scalar_product(1.0/norm, use));
        }
      } 

      template <typename RequestedTT>
      std::vector<RequestedTT> get_topic_etas() {
	std::vector< RequestedTT > topics;
	for(auto& sage_topic : topics_) {
	  topics.push_back(sage_topic->template eta_as< RequestedTT >(true));
	}
	return topics;
      }

      void update_model(M* m, bool heldout = false) {
	if(!heldout) {
	  std::vector< ModelTopicType > topics;
	  for(auto& sage_topic : topics_) {
	    topics.push_back(sage_topic->template eta_as< ModelTopicType >(true));
	  }
	  m->prior_word(topics);
	}
        std::vector<std::vector<double> > usage;
        this->get_usage_estimates(&usage);
        m->prior_topic(usage);
      }
      void update_model(bool heldout = false) {
        update_model(model_, heldout);
      }

      void update_usage_frobenius(double* frob_diff) {
        std::vector<std::vector<double> > usages;
        this->get_usage_estimates(&usages);
        if(prev_usages.size() > 0) {
          // calculate frob(prev - val)
          const size_t M = usages.size();
          const size_t N = usages[0].size();
          double val = 0.0;
          for(size_t m = 0; m < M; ++m) {
            const std::vector<double>& prow = prev_usages[m];
            const std::vector<double>& urow = usages[m];
            for(size_t n = 0; n < N; ++n) {
              const double x = prow[n] - urow[n];
              val += x*x;
            }
          }
          *frob_diff = sqrt(val);
        } else {
          *frob_diff = isage::util::frobenius_norm(usages);          
        }
        INFO << "Topic usage Frobenius norm is " << (*frob_diff);
        prev_usages = usages;
      }

      inline void e_step(const SageStrategy& strategy) {
	renormalize_topics();
        if(strategy.em_verbosity >= 1) {
          INFO << "E-step";
        }
	for(int e_iter = 0; e_iter < strategy.num_e_iters; ++e_iter) {
          if(strategy.em_verbosity >= 2) {
            INFO << "\tE-step sub-iteration number " << e_iter;
          }
          zero_expected_counts();
	  omp_set_num_threads(strategy.num_e_threads);
#pragma omp parallel for
          for(int di = 0; di < num_docs_; ++di){
            if(strategy.em_verbosity >= 3 && di % 1000 == 0) {
              INFO << "\t\tDocument " << di << " of iteration " << e_iter;
            }
            std::vector<double> usage_grad = 
              dmc::dirichlet::grad_log_partition_static(var_topic_usage_params_[di]);

	    // iterate through all word types in the document
	    // note that this is sparse
	    const std::vector<int>& words = words_in_docs_[di];
	    const std::vector<WordCountType>& wcounts = word_type_counts_[di];

	    const size_t wid = words.size();

	    // initialize the assignment params
	    std::vector< std::vector< double > > var_assignment_params(wid, usage_grad);
	    
	    for(size_t i = 0; i < wid; ++i) {
	      const int word = words[i];
	      const int word_count = wcounts[i];
	      expected_mutexes_[word].lock();
	      update_var_assignments(di, word, word_count,
                                     &(var_assignment_params[i]));
	      expected_mutexes_[word].unlock();
	    }
	    update_usage(di, var_assignment_params);
	  }
	}
      }

      // The basic idea here is to do a one-iteration 
      // warm-start M-step.
      void m_step(const SageStrategy& strategy) {
        if(strategy.em_verbosity >= 1) {
          INFO << "M-step";
        }
	for(int m_iter = 0; m_iter < strategy.num_m_iters; ++m_iter) {
          if(strategy.em_verbosity >= 2) {
            INFO << "\tM-step sub-iteration number " << m_iter;
          }
	  // first update the etas
	  update_topics(strategy);
	  // then update tau... except following the SAGE 
          // implementation, since we're using the improper
          // Jeffrey's prior, we don't have to.
	}
        // compute topic density
        const double thresh = strategy.eta_density_threshold;
        int num_above = 0;
        for(int t = 0; t < num_topics_; ++t) {
          for(const auto& val : topics_[t]->eta()) {
            if(abs(val) > thresh) ++num_above;
          }
        }
        INFO << "Topic density is " << ((double)num_above / (double)( num_topics_ * vocab_->num_words())) << ", at threshold = " << thresh;
      }

      inline void update_hypers() {
	typedef dmc::DirichletVariationalClosure ClosureType;
	ClosureType closure;
	closure.variational_params = &var_topic_usage_params_;
	// INFO << "The closure suff. stats are: ";
	// isage::util::print_2d(var_topic_usage_params_);
	double f_init = dmc::dirichlet::hyperparameters_variational_objective(usage_hypers_, &closure);
	std::vector<double> point = dmc::dirichlet::hyperparameters_variational_nr(usage_hypers_, &closure);
	double f_end = dmc::dirichlet::hyperparameters_variational_objective(point, &closure);
	const double dist = isage::util::dist(usage_hypers_, point);
	INFO << "Hyperparameter optimization moved the alpha point " << dist << " units away";
	INFO << "Hyperparameter optimization moved the value " << (f_end - f_init) << ", from " << f_init << " to " << f_end;
	usage_hypers_ = point;
      }

      void learn_all(const SageStrategy& strategy, int epoch = 0,
		     isage::util::SmartWriter usage_smart_wr = isage::util::SmartWriter("/dev/null"),
		     isage::util::SmartWriter topic_smart_wr = isage::util::SmartWriter("/dev/null"),
		     isage::util::SmartWriter assign_smart_wr = isage::util::SmartWriter("/dev/null")) {
        int learn_iter = 0;
        double fro_diff = std::numeric_limits<double>::max();
	bool last_iter = false;
	bool force_update = false;
	bool model_changed = false;
	if(topic_smart_wr.to_file()) {
	  std::vector< ModelTopicType > topics;
	  for(auto& sage_topic : topics_) {
	    // but we won't normalize
	    topics.push_back(sage_topic->template eta_as< ModelTopicType >(false));
	  }
	  std::string suff = "epoch" + std::to_string(epoch) + ".emiter0";
	  std::ostream& out_stream = topic_smart_wr.get(suff);
	  INFO << "Writing initial topic output to " << topic_smart_wr.name();
	  model_->print_topics(out_stream, *vocab_, topics);
	}

	while(learn_iter++ < strategy.num_learn_iters && 
	      fro_diff > strategy.em_frobenius_threshold) {
 	  last_iter = learn_iter >= strategy.num_learn_iters;
	  // do the main learning and optimization
	  {
	    if(strategy.em_verbosity >= 0) {
	      INFO << "EM step " << learn_iter;
	    }
	    e_step(strategy);
	    if(! strategy.heldout) {
	      m_step(strategy);
	    }
	    if( strategy.hyper_update_iter > 0 && 
		( (learn_iter > strategy.hyper_update_min 
		   && learn_iter % strategy.hyper_update_iter == 0 )
		  || last_iter) ) {
	      update_hypers();
	      force_update = true;
	      model_changed = true;
	    }
	    update_usage_frobenius(&fro_diff);
	  }
	  // now do various printing options
	  {
	    if(true || learn_iter % strategy.update_model_every == 0 || force_update || last_iter) {
	      update_model(strategy.heldout);
	      model_changed = true;
	    }
	    if(learn_iter % strategy.print_topics_every == 0 || last_iter) {
	      // if we haven't updated, then we should get some form of the current topics
	      if(learn_iter % strategy.update_model_every) {
		std::vector< ModelTopicType > topics;
		for(auto& sage_topic : topics_) {
		  // but we won't normalize
		  topics.push_back(sage_topic->template eta_as< ModelTopicType >(false));
		}
		model_->print_topics(strategy.print_topics_k, *vocab_, topics);
		if(topic_smart_wr.to_file()) {
		  std::string suff = "epoch" + std::to_string(epoch) + ".emiter" + std::to_string(learn_iter);
		  std::ostream& out_stream = topic_smart_wr.get(suff);
		  INFO << "Writing topic posterior output to " << topic_smart_wr.name();
		  model_->print_topics(out_stream, *vocab_, topics);
		}
	      } else {
		model_->print_topics(strategy.print_topics_k, *vocab_);
		if(topic_smart_wr.to_file()) {
		  std::string suff = "epoch" + std::to_string(epoch) + ".emiter" + std::to_string(learn_iter);
		  std::ostream& out_stream = topic_smart_wr.get(suff);
		  INFO << "Writing topic posterior output to " << topic_smart_wr.name();
		  model_->print_topics(out_stream, *vocab_);
		}
	      }
	    }
	    if( (learn_iter % strategy.print_usage_every == 0) || 
		model_changed || last_iter) {
	      std::string suff = "epoch" + std::to_string(epoch) + ".emiter" + std::to_string(learn_iter);
	      std::ostream& out_stream = usage_smart_wr.get(suff);
	      INFO << "Writing topic usage output to " << usage_smart_wr.name();
	      model_->print_usage(out_stream);
	    }
	  }
	}
	// always update the model at the very end
	update_model(strategy.heldout);
      }

      void learn(const SageStrategy& strategy, int epoch = 0,
		 isage::util::SmartWriter usage_smart_wr = isage::util::SmartWriter("/dev/null"),
		 isage::util::SmartWriter topic_smart_wr = isage::util::SmartWriter("/dev/null"),
		 isage::util::SmartWriter assign_smart_wr = isage::util::SmartWriter("/dev/null")) {
	// at first, proceed normally: estimate both the local and global (topic) parameters
	isage::util::SmartWriter i_usage_wr(usage_smart_wr.base_name() + "_initial");
	isage::util::SmartWriter i_assign_wr(assign_smart_wr.base_name() + "_initial");
	isage::util::SmartWriter i_topic_wr(topic_smart_wr.base_name() + "_initial");
	learn_all(strategy, epoch, i_usage_wr,
			 i_topic_wr, i_assign_wr);
	if(strategy.partial_restarts > 0) {
	  SageStrategy r_strat(strategy);
	  r_strat.num_learn_iters = strategy.num_learn_restart_iters;
	  r_strat.num_e_iters = strategy.num_e_restart_iters;
	  r_strat.heldout = true;
	  std::vector<std::vector<double> > averaged_usage_params(var_topic_usage_params_);
	  isage::wtm::SageInitializer reiniter(num_topics_);
	  INFO << "number of restarts to do " << strategy.partial_restarts;
	  for(int restart_num = 1; restart_num <= strategy.partial_restarts; ++restart_num) {
	    INFO << "Partial restart " << restart_num;
	    // now reset the usage parameters
	    // as this is the limited memory version, the assignment 
	    // parameters are handled later
	    for(int d = 0; d < num_docs_; d++) {
	      const auto& doc = (*corpus_)[d];
	      var_topic_usage_params_[d] = reiniter.usage(model_->hyper_theta(), doc.num_words());
	    }
	    std::string runame = usage_smart_wr.base_name() + "_restart" + std::to_string(restart_num);
	    isage::util::SmartWriter r_usage_wr(runame);
	    std::string raname = assign_smart_wr.base_name() + "_restart" + std::to_string(restart_num);
	    isage::util::SmartWriter r_assign_wr(raname);
	    learn_all(r_strat, epoch, r_usage_wr, 
		      isage::util::SmartWriter("/dev/null"), r_assign_wr);
	    // now get the usage parameters and add to the running average
	    for(int d = 0; d < num_docs_; ++d) {
	      isage::util::sum_in_first(&(averaged_usage_params[d]),
					var_topic_usage_params_[d]);
	    }
	  } // end for(int r = 0; r < strategy.partial_restarts; ++r)
	  // and now average
	  const double iR = 1.0/(double)strategy.partial_restarts;
	  for(int d = 0; d < num_docs_; ++d) {
	    isage::util::scalar_product(iR, &(averaged_usage_params[d]));
	  }
	  // finally, transfer the averaged parameters back
	  var_topic_usage_params_ = averaged_usage_params;
	  // update the model
	  update_model(r_strat.heldout);
	  // and print
	  std::string suff = "epoch" + std::to_string(epoch) + ".averaged";
	  std::ostream& out_stream = usage_smart_wr.get(suff);
	  INFO << "Writing AVERAGED topic usage output to " << usage_smart_wr.name();
	  model_->print_usage(out_stream);
	} // end if(partial_restarts > 0)
      }

      void learn() {
        const SageStrategy strategy;
        learn(strategy);
      }

    };
  }
}
#endif
